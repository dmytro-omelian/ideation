{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:21:27.178234Z",
     "start_time": "2023-12-27T06:21:26.932925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME: /Users/tarasbohdan/Desktop/projects/idea-contest-2023/ideation-api\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: You are using pip version 21.1.1; however, version 23.3.2 is available.\r\n",
      "You should consider upgrading via the '/Users/tarasbohdan/Desktop/projects/idea-contest-2023/ideation-api/venv/bin/python3.8 -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:21:41.933344Z",
     "start_time": "2023-12-27T06:21:30.804178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "!mkdir -p {HOME}/weights\n",
    "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:27:35.964744Z",
     "start_time": "2023-12-27T06:21:44.364236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tarasbohdan/Desktop/projects/idea-contest-2023/ideation-api/weights/sam_vit_h_4b8939.pth ; exist: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:27:36.006740Z",
     "start_time": "2023-12-27T06:27:35.987294Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarasbohdan/Desktop/projects/idea-contest-2023/ideation-api/venv/lib/python3.8/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_h\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:29:18.542884Z",
     "start_time": "2023-12-27T06:29:15.935600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:31:25.663472Z",
     "start_time": "2023-12-27T06:30:53.454969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:46:11.273044Z",
     "start_time": "2023-12-27T06:46:11.257641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg -P {HOME}/data\n",
    "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg -P {HOME}/data\n",
    "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg -P {HOME}/data\n",
    "!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg -P {HOME}/data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:37:51.369336Z",
     "start_time": "2023-12-27T06:37:47.166717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IMAGE_NAME = \"dog.jpeg\"\n",
    "IMAGE_PATH = os.path.join(HOME, \"data\", IMAGE_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:46:14.902648Z",
     "start_time": "2023-12-27T06:46:14.878178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:53:04.140886Z",
     "start_time": "2023-12-27T06:53:04.066684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "test = image_bgr.astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:37.254197Z",
     "start_time": "2023-12-27T06:42:37.202376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720, 3)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(image_rgb.shape)\n",
    "print(image_rgb.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:43:54.910736Z",
     "start_time": "2023-12-27T06:43:54.862189Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:48:23.289752Z",
     "start_time": "2023-12-27T06:48:22.605749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of numpy.uint8",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sam_result \u001B[38;5;241m=\u001B[39m \u001B[43mmask_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_rgb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/projects/idea-contest-2023/ideation-api/venv/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/projects/idea-contest-2023/ideation-api/venv/lib/python3.8/site-packages/segment_anything/automatic_mask_generator.py:163\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator.generate\u001B[0;34m(self, image)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03mGenerates masks for the given image.\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m         the mask, given in XYWH format.\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;66;03m# Generate masks\u001B[39;00m\n\u001B[0;32m--> 163\u001B[0m mask_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_masks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# Filter small disconnected regions and holes in masks\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_mask_region_area \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Desktop/projects/idea-contest-2023/ideation-api/venv/lib/python3.8/site-packages/segment_anything/automatic_mask_generator.py:206\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator._generate_masks\u001B[0;34m(self, image)\u001B[0m\n\u001B[1;32m    204\u001B[0m data \u001B[38;5;241m=\u001B[39m MaskData()\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m crop_box, layer_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(crop_boxes, layer_idxs):\n\u001B[0;32m--> 206\u001B[0m     crop_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_crop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrop_box\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morig_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    207\u001B[0m     data\u001B[38;5;241m.\u001B[39mcat(crop_data)\n\u001B[1;32m    209\u001B[0m \u001B[38;5;66;03m# Remove duplicate masks between crops\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/projects/idea-contest-2023/ideation-api/venv/lib/python3.8/site-packages/segment_anything/automatic_mask_generator.py:236\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator._process_crop\u001B[0;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001B[0m\n\u001B[1;32m    234\u001B[0m cropped_im \u001B[38;5;241m=\u001B[39m image[y0:y1, x0:x1, :]\n\u001B[1;32m    235\u001B[0m cropped_im_size \u001B[38;5;241m=\u001B[39m cropped_im\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m--> 236\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcropped_im\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# Get points for this crop\u001B[39;00m\n\u001B[1;32m    239\u001B[0m points_scale \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(cropped_im_size)[\u001B[38;5;28;01mNone\u001B[39;00m, ::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/projects/idea-contest-2023/ideation-api/venv/lib/python3.8/site-packages/segment_anything/predictor.py:57\u001B[0m, in \u001B[0;36mSamPredictor.set_image\u001B[0;34m(self, image, image_format)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Transform the image to the form expected by the model\u001B[39;00m\n\u001B[1;32m     56\u001B[0m input_image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mapply_image(image)\n\u001B[0;32m---> 57\u001B[0m input_image_torch \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m input_image_torch \u001B[38;5;241m=\u001B[39m input_image_torch\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()[\u001B[38;5;28;01mNone\u001B[39;00m, :, :, :]\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_torch_image(input_image_torch, image\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m])\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Could not infer dtype of numpy.uint8"
     ]
    }
   ],
   "source": [
    "sam_result = mask_generator.generate(image_rgb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:53:20.196822Z",
     "start_time": "2023-12-27T06:53:20.069277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sam_result[0].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-27T06:34:07.832321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "\n",
    "detections = sv.Detections.from_sam(sam_result=sam_result)\n",
    "\n",
    "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=[image_bgr, annotated_image],\n",
    "    grid_size=(1, 2),\n",
    "    titles=['source image', 'segmented image']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
